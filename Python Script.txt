# %% [markdown]
# ## IMPORTING LIBRARIES 

# %%
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
# Import BaseSettings from pydantic_settings
%pip install ydata_profiling
from ydata_profiling import ProfileReport


# %% [markdown]
# ## IMPORTING DATASETS

# %%
# Reading The Data By Pandas
data=pd.read_csv("D:\MAIN DRIVE\VSCODE\Regression-Project\data.csv")
# Creating 'X' Matrix For Independent Features In The Dataset
X=data.iloc[:,:-1].values
# Creating 'Y' Matrix For Independent Features In The Dataset
Y=data.iloc[:,-1].values

# %% [markdown]
# ## GENRATING PROFILE USING PANDAS PROFILING

# %%
profile=ProfileReport(data)
profile.to_notebook_iframe()

# %% [markdown]
# ## <!-- Attribute Information:
# 
#     1. CRIM      per capita crime rate by town
#     2. ZN        proportion of residential land zoned for lots over 25,000 sq.ft.
#     3. INDUS     proportion of non-retail business acres per town
#     4. CHAS      Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)                
#     5. NOX       nitric oxides concentration (parts per 10 million)
#     6. RM        average number of rooms per dwelling
#     7. AGE       proportion of owner-occupied units built prior to 1940
#     8. DIS       weighted distances to five Boston employment centres
#     9. RAD       index of accessibility to radial highways
#     10. TAX      full-value property-tax rate per $10,000
#     11. PTRATIO  pupil-teacher ratio by town
#     12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
#     13. LSTAT    % lower status of the population
#     14. MEDV     Median value of owner-occupied homes in $1000's --> 
# ##

# %%
data

# %%
data.info()

# %%
# "CHAR" IS A UNBALANCED COLUMN <BIASED>
data['CHAS'].value_counts()


# %%
data.describe()

# %% [markdown]
# ## VISUALIZING THE DATASET 

# %%
#For plotting histogram
print("HISTOGRAM")
%matplotlib inline
data.hist(bins=50, figsize=(20, 15))

# %%
print("COLORED - BOXPLOT")
sns.boxplot(data=data)


# %%
print("PAIR - PLOT OF ALL FEATURES WITH LABEL")
sns.pairplot(data)


# %%
print("HEATMAP")
sns.heatmap(data.corr(), annot=True)


# %%
print("Density - Plot")
sns.kdeplot(data, fill=True)


# %% [markdown]
# ## INDEPENDENT - FEATURES & DEPENDENT - LABEL

# %%
print(F"Matrix For Independent Features In The Dataset -> \n{X}")

# %%
print(F"Matrix For Dependent Features In The Dataset -> MEVD \n{Y.reshape(len(Y),1)}")

# %% [markdown]
# ## VALIDATING THE MISSING VALUES IN THE DATASET 

# %%
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
X[:, :14] = imputer.fit_transform(X[:, :14])

# %%
print(F"AFTER VALIDATING THE MISSING VALUES IN 'x' MATRIX : \n{X} ")

# %% [markdown]
# ## < NO ENCODNG IS NEEDED >

# %% [markdown]
# ## TRAIN AND TEST SPLIT 

# %%
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)

# %%
print(F"The Independent Training Set :{X_train.shape} \n{X_train}") # Printing The Independent Training Set

# %%
print(F"The Dependent Training Set : {Y_train.shape} \n{Y_train}") # Printing The Dependent Training Set

# %%
print(F"The Independent Testing Set :{X_test.shape} \n{X_test}") # Printing The Independent Testing Set

# %%
print(F"The Dependent Testing Set : {Y_test.shape} \n{Y_test}") # Printing The Independent Testing Set

# %% [markdown]
# ## Resolved The Unbalanced Column 'CHAS'

# %%
# Convert it to a pandas Series
X_train_series = pd.DataFrame(X_train)

# Now you can use value_counts() on the Series
counts = X_train_series[3].value_counts()

print(counts)

# %%
# Convert it to a pandas Series
X_test_series = pd.DataFrame(X_test)

# Now you can use value_counts() on the Series
counts = X_test_series[3].value_counts()

print(counts)

# %%
print(F"Ratio Of The CHAS IN X_train : {95//7}")

# %%
print(F"Ratio Of The CHAS IN X_train : {376//28}")


# %% [markdown]
# ## The "CHAS" Is Been Resolved And It Has been Splited Evenly In Both 'X_train' & 'X_test' Respectively ABOVE

# %% [markdown]
# ## FEATURE SCALING

# %%
from sklearn.preprocessing import StandardScaler
FS=StandardScaler()
X_FS= FS.fit_transform(X_train)
Y_FS = FS.fit_transform(Y_train.reshape(len(Y_train),-1))

# %%
print(F"Featured Scaled Values of X_train  :{X_FS.shape} \n{X_FS}")

# %%
print(F"Featured Scaled Values of Y_train  :{Y_FS.shape} \n{Y_FS}")

# %% [markdown]
# ## MODEL SELECTION < SELECTIVE BEST ,< AS PER GIVEN DATA >

# %% [markdown]
# LINEAR REGRESSION MODEL 

# %%
from sklearn.linear_model import LinearRegression
LR=LinearRegression()
LR.fit(X_train, Y_train)

# %% [markdown]
# ## Predicting the Test set results  < LINEAR REGRESSION >

# %%
Y_pred = LR.predict(X_test)
np.set_printoptions(precision=2)
print(np.concatenate((Y_pred.reshape(len(Y_pred),1), Y_test.reshape(len(Y_test),1)),1))

# %% [markdown]
# ## Evaluating the Model Performance < LINEAR REGRESSION >

# %%
from sklearn.metrics import r2_score

# Assuming RMS is the R^2 score
RMS = r2_score(Y_test, Y_pred)

# Format the RMS value with two decimal points
formatted_RMS = "{:.2f}".format(RMS)

# Convert formatted_RMS to float for comparison
formatted_RMS_float = float(formatted_RMS)
if formatted_RMS_float==1:
    print(f"The R^2 Score {formatted_RMS} %   'Over Fitted Model'")
elif 0.8 < formatted_RMS_float < 0.9:
    print(f"The R^2 Score {formatted_RMS} %   'Perfect Model'")
elif 0.7 < formatted_RMS_float < 0.8:
    print(f"The R^2 Score {formatted_RMS} %   'accurate Model'")
elif 0.6 < formatted_RMS_float <0.7:
    print(f"The R^2 Score {formatted_RMS} %   'Modrate Model'")
elif 0.5< formatted_RMS_float < 0.6:
    print(f"The R^2 Score {formatted_RMS} %   'Under Fitted Model'")
else:
    print(f"The R^2 Score {formatted_RMS} %    'Weak Model'")


# %% [markdown]
# ## 

# %% [markdown]
# ## SELECTED MODEL < DECISION REGRESSION >

# %%
from sklearn.tree import DecisionTreeRegressor
DT= DecisionTreeRegressor(random_state = 0)
DT.fit(X_train, Y_train)

# %% [markdown]
# ## Predicting the Test set results  < DECISION REGRESSION >

# %%
Y_pred = DT.predict(X_test)
np.set_printoptions(precision=2)
print(np.concatenate((Y_pred.reshape(len(Y_pred),1), Y_test.reshape(len(Y_test),1)),1))

# %% [markdown]
# ## Evaluating the Model Performance < DECISION REGRESSION >

# %%
from sklearn.metrics import r2_score

# Assuming RMS is the R^2 score
RMS = r2_score(Y_test, Y_pred)

# Format the RMS value with two decimal points
formatted_RMS = "{:.2f}".format(RMS)

# Convert formatted_RMS to float for comparison
formatted_RMS_float = float(formatted_RMS)
if formatted_RMS_float==1.0:
    print(f"The R^2 Score {formatted_RMS} %   'Over Fitted Model'")
elif 0.8 < formatted_RMS_float < 0.9:
    print(f"The R^2 Score {formatted_RMS} %   'Perfect Model'")
elif 0.7 < formatted_RMS_float < 0.8:
    print(f"The R^2 Score {formatted_RMS} %   'accurate Model'")
elif 0.6 < formatted_RMS_float <0.7:
    print(f"The R^2 Score {formatted_RMS} %   'Modrate Model'")
elif 0.0 < formatted_RMS_float < 0.5:
    print(f"The R^2 Score {formatted_RMS} %   'Under Fitted Model'")
elif formatted_RMS_float < 0.0:
    print(f"The R^2 Score {formatted_RMS} %   'BAD Model'")
else:
    print(f"The R^2 Score {formatted_RMS} %    'Weak Model'")


# %% [markdown]
# ## SELECTED MODEL < RANDOM FOREST REGRESSION >

# %%
from sklearn.ensemble import RandomForestRegressor
RFR = RandomForestRegressor(n_estimators = 5000, random_state = 0)
RFR.fit(X_train, Y_train)

# %% [markdown]
# ## Predicting the Test set results  < RANDOM FOREST REGRESSION >

# %%
Y_predRFR = RFR.predict(X_test)
np.set_printoptions(precision=2)
print(np.concatenate((Y_predRFR.reshape(len(Y_predRFR),1), Y_test.reshape(len(Y_test),1)),1))

# %% [markdown]
# ## Evaluating the Model Performance < RANDOM FOREST REGRESSION >

# %%
from sklearn.metrics import r2_score

# Assuming RMS is the R^2 score
RMS = r2_score(Y_test, Y_predRFR)

# Format the RMS value with two decimal points
formatted_RMS = "{:.2f}".format(RMS)

# Convert formatted_RMS to float for comparison
formatted_RMS_float = float(formatted_RMS)
if formatted_RMS_float==1.0:
    print(f"The R^2 Score {formatted_RMS} %   'Over Fitted Model'")
elif 0.9 < formatted_RMS_float < 1:
    print(f"The R^2 Score {formatted_RMS} %   'Perfect Model'")
elif 0.8 < formatted_RMS_float < 0.9:
    print(f"The R^2 Score {formatted_RMS} %   'accurate Model'")
elif 0.7 < formatted_RMS_float <0.8:
    print(f"The R^2 Score {formatted_RMS} %   'Modrate Model'")
elif 0.5 < formatted_RMS_float < 0.6:
    print(f"The R^2 Score {formatted_RMS} %   'Under Fitted Model'")
elif formatted_RMS_float < 0.0:
    print(f"The R^2 Score {formatted_RMS} %   'BAD Model'")
else:
    print(f"The R^2 Score {formatted_RMS} %    'Weak Model'")


# %% [markdown]
# ## Grid Search CV

# %%
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

# Define the parameter grid
parameters = {
    'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],
    'criterion': ["squared_error", "absolute_error", "friedman_mse", "poisson"], 
    'max_depth': [20]
}

# Initialize a RandomForestRegressor (you can choose any model)
model = RandomForestRegressor()

# Initialize GridSearchCV with the model, parameter grid, and any other necessary arguments
GCV = GridSearchCV(estimator=model, param_grid=parameters, cv=5)  # cv is the number of folds for cross-validation
GCV.fit(X_train,Y_train)

# %%
Best_prarm=GCV.best_params_
print(Best_prarm)

# %%
Y_predGCV = GCV.predict(X_test)
np.set_printoptions(precision=2)
print(np.concatenate((Y_predRFR.reshape(len(Y_predRFR),1), Y_test.reshape(len(Y_test),1)),1))

# %% [markdown]
# ## Score

# %%
G=GCV.best_score_
print(G)

# %% [markdown]
# ## SAVING THE  Grid Search CV 

# %%
from joblib import dump, load
dump(GCV, 'REAL.joblib') 

# %% [markdown]
# ## USING THE MODEL

from joblib import dump, load
import numpy as np
GCV = load('REAL.joblib') 
features = np.array([[-5.43942006, 4.12628155, -1.6165014, -0.67288841, -1.42262747,
       -11.44443979304, -49.31238772,  7.61111401, -26.0016879 , -0.5778192 ,
       -0.97491834,  0.41164221, -66.86091034]])
K=GCV.predict(features)
PRICE=(int(K)*1000)
print(K)

# %% [markdown]
# ## [29.55] By GCV

# %% [markdown]
# ## [30.12] RFR

# %%
print(F"THE PRICE OF THE HOUSE IS {PRICE} $ IN BOSTON CITY")


# %% [markdown]
# ##  BY RFR <24,39,720 RUPEES> / < 30000 > / /  BY GCV <24,07,951  RUPEES>/<29000 >

# %% [markdown]
# 


